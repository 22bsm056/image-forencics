"""
Image Malware Detection Module - Digital Forensics Project
This module analyzes image files for potential hidden malicious content (steganography)
"""

import os
import re
import logging
import binascii
import hashlib
import struct
import math
from collections import Counter
import magic
import zlib

class ImageMalwareDetection:
    def __init__(self, file_path):
        """Initialize with the path to the image file for analysis"""
        self.file_path = file_path
        self.file_exists = os.path.exists(file_path)
        self.results = {}
        self.file_data = None
        self.hex_data = None
        
        # Supported image formats and their signatures
        self.image_signatures = {
            "jpeg": [b'\xFF\xD8\xFF', b'\xFF\xD9'],
            "png": [b'\x89PNG\r\n\x1A\n', b'IEND\xAE\x42\x60\x82'],
            "gif": [b'GIF87a', b'GIF89a'],
            "bmp": [b'BM', None],
            "webp": [b'RIFF', None],
            "tiff": [b'II*\x00', b'MM\x00*']
        }
        
        # Patterns to detect code hiding in images
        self.code_signatures = {
            "php_code": re.compile(rb'<\?php.*?\?>', re.DOTALL | re.IGNORECASE),
            "javascript": re.compile(rb'<script.*?>.*?</script>', re.DOTALL | re.IGNORECASE),
            "javascript_eval": re.compile(rb'eval\s*\(.*?\)', re.DOTALL | re.IGNORECASE),
            "shell_commands": re.compile(rb'system\s*\(|exec\s*\(|shell_exec\s*\(|passthru\s*\(', re.IGNORECASE),
            "powershell_encoded": re.compile(rb'-e(?:ncodedcommand)?\s+[A-Za-z0-9+/=]{20,}', re.IGNORECASE),
            "executable_header": re.compile(rb'MZ.{50,200}PE\x00\x00', re.DOTALL),
            "elf_header": re.compile(rb'\x7FELF', re.DOTALL),
            "python_code": re.compile(rb'import\s+os|subprocess\.call|exec\s*\(|eval\s*\(', re.IGNORECASE),
            "shellcode": re.compile(rb'\\x[0-9a-f]{2}\\x[0-9a-f]{2}\\x[0-9a-f]{2}(\\x[0-9a-f]{2}){5,}', re.IGNORECASE)
        }
        
        # File inclusion patterns
        self.inclusion_patterns = re.compile(rb'include\s*\(|require\s*\(|include_once\s*\(|require_once\s*\(', re.IGNORECASE)
        
        # URL and network indicators
        self.network_patterns = re.compile(rb'https?://|connect\s*\(|socket\s*\(', re.IGNORECASE)
        
        # Set up logging
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger("ImageMalwareDetection")
    
    def analyze_image(self):
        """Main analysis method for image files"""
        if not self.file_exists:
            self.logger.error(f"File not found: {self.file_path}")
            return {"error": "File not found"}
        
        try:
            # Read file content
            with open(self.file_path, 'rb') as f:
                self.file_data = f.read()
                # Convert to hex for some analysis
                self.hex_data = binascii.hexlify(self.file_data).decode('utf-8')
            
            # Verify it's an image file
            is_image = self.verify_image_file()
            if not is_image["is_valid_image"]:
                return {"error": f"Not a valid image file: {is_image['reason']}"}
            
            # Run various detection methods
            self.results["file_verification"] = is_image
            self.results["steganography_analysis"] = self.detect_steganography()
            self.results["malicious_code_check"] = self.check_for_malicious_code()
            self.results["metadata_analysis"] = self.analyze_metadata()
            self.results["hidden_data_analysis"] = self.check_for_hidden_data()
            
            # Overall risk assessment
            self.results["risk_assessment"] = self.assess_risk()
            
            return self.results
            
        except Exception as e:
            self.logger.error(f"Error analyzing image: {str(e)}")
            return {"error": f"Error analyzing image: {str(e)}"}
    
    def verify_image_file(self):
        """Verify that the file is indeed an image"""
        result = {
            "is_valid_image": False,
            "detected_format": None,
            "file_extension": os.path.splitext(self.file_path)[1].lower()
        }
        
        # Check magic bytes to identify file type
        for img_type, signatures in self.image_signatures.items():
            if signatures[0] and self.file_data.startswith(signatures[0]):
                result["is_valid_image"] = True
                result["detected_format"] = img_type
                break
        
        # Double check with magic library
        try:
            mime = magic.Magic(mime=True)
            detected_type = mime.from_buffer(self.file_data)
            result["mime_type"] = detected_type
            
            # Verify mime type matches an image
            if not detected_type.startswith('image/'):
                result["type_mismatch_warning"] = f"File has image signature but MIME type is: {detected_type}"
        except:
            result["mime_check"] = "Failed - magic library unavailable"
        
        # Check extension matches format
        if result["is_valid_image"]:
            expected_extensions = {
                "jpeg": [".jpg", ".jpeg", ".jpe", ".jfif"],
                "png": [".png"],
                "gif": [".gif"],
                "bmp": [".bmp"],
                "webp": [".webp"],
                "tiff": [".tif", ".tiff"]
            }
            
            if result["detected_format"] in expected_extensions:
                if result["file_extension"] not in expected_extensions[result["detected_format"]]:
                    result["extension_mismatch"] = True
                    result["expected_extensions"] = expected_extensions[result["detected_format"]]
        else:
            result["reason"] = "No valid image signature detected"
            
        return result
    
    def detect_steganography(self):
        """Detect signs of steganography in image files"""
        results = {}
        
        # Get file format
        img_format = self.results["file_verification"]["detected_format"]
        if not img_format:
            return {"error": "Cannot analyze unknown image format"}
        
        # Calculate entropy as baseline indicator
        overall_entropy = self.shannon_entropy(self.file_data)
        results["overall_entropy"] = overall_entropy
        
        # Interpretation of entropy value for images
        if overall_entropy > 7.9:
            results["entropy_assessment"] = "Extremely high entropy - strongly indicates encrypted content or steganography"
        elif overall_entropy > 7.7:
            results["entropy_assessment"] = "Very high entropy - possibly indicates hidden content"
        elif overall_entropy > 7.0:
            results["entropy_assessment"] = "High entropy - typical for compressed images"
        else:
            results["entropy_assessment"] = "Normal entropy - no indication of hidden content based on entropy alone"
        
        # Format-specific checks
        if img_format == "jpeg":
            results["jpeg_analysis"] = self.analyze_jpeg_file()
        elif img_format == "png":
            results["png_analysis"] = self.analyze_png_file()
        elif img_format == "gif":
            results["gif_analysis"] = self.analyze_gif_file()
        
        # Check for data after EOF marker
        if img_format in self.image_signatures and self.image_signatures[img_format][1]:
            eof_marker = self.image_signatures[img_format][1]
            if eof_marker in self.file_data:
                eof_pos = self.file_data.rindex(eof_marker) + len(eof_marker)
                
                if eof_pos < len(self.file_data):
                    appended_data = self.file_data[eof_pos:]
                    results["appended_data"] = {
                        "found": True,
                        "size": len(appended_data),
                        "position": eof_pos,
                        "entropy": self.shannon_entropy(appended_data),
                        "preview_hex": binascii.hexlify(appended_data[:32]).decode('ascii')
                    }
                    
                    # Try to detect content type of appended data
                    results["appended_data"]["content_indicators"] = self.detect_appended_content_type(appended_data)
        
        return results
    
    def detect_appended_content_type(self, data):
        """Try to determine what type of content is appended to the image"""
        indicators = []
        
        # Check for known file signatures
        if data.startswith(b'PK\x03\x04'):
            indicators.append("ZIP archive or Office document")
        elif data.startswith(b'MZ'):
            indicators.append("Windows executable (PE)")
        elif data.startswith(b'\x7FELF'):
            indicators.append("Linux executable (ELF)")
        elif data.startswith(b'%PDF'):
            indicators.append("PDF document")
        elif b'<html' in data[:100] or b'<!DOCTYPE' in data[:100]:
            indicators.append("HTML content")
        elif b'<?php' in data[:100]:
            indicators.append("PHP code")
        elif data.startswith(b'#!/'):
            indicators.append("Shell script")
        
        # Check for base64 encoded data
        base64_pattern = re.compile(rb'^[A-Za-z0-9+/]{20,}={0,2}$')
        if base64_pattern.match(data.strip()):
            indicators.append("Base64 encoded data")
        
        # Check for script patterns
        for name, pattern in self.code_signatures.items():
            if pattern.search(data):
                indicators.append(f"Contains {name.replace('_', ' ')}")
        
        return indicators if indicators else ["Unknown binary data"]
    
    def analyze_jpeg_file(self):
        """Analyze JPEG file for anomalies and hidden content"""
        results = {}
        
        # JPEG structure analysis
        segments = []
        
        try:
            # Skip the SOI marker
            pos = 2
            
            while pos < len(self.file_data):
                # Find next marker
                if self.file_data[pos] != 0xFF:
                    pos += 1
                    continue
                
                # Skip padding
                if self.file_data[pos] == 0xFF and self.file_data[pos+1] == 0x00:
                    pos += 2
                    continue
                
                # Get marker and segment length
                marker = self.file_data[pos:pos+2]
                marker_name = self.get_jpeg_marker_name(marker)
                
                # SOI, EOI have no length
                if marker in [b'\xFF\xD8', b'\xFF\xD9']:
                    segments.append({
                        "marker": marker.hex(),
                        "marker_name": marker_name,
                        "offset": pos
                    })
                    pos += 2
                    
                    # If EOI, break
                    if marker == b'\xFF\xD9':
                        break
                # Other segments have length
                else:
                    if pos + 4 <= len(self.file_data):
                        length = struct.unpack('>H', self.file_data[pos+2:pos+4])[0]
                        
                        segment_data = {
                            "marker": marker.hex(),
                            "marker_name": marker_name,
                            "offset": pos,
                            "length": length
                        }
                        
                        # For comment segments, add preview
                        if marker == b'\xFF\xFE':
                            comment_data = self.file_data[pos+4:pos+2+length]
                            segment_data["comment_preview"] = comment_data[:50].decode('ascii', errors='replace')
                            segment_data["comment_entropy"] = self.shannon_entropy(comment_data)
                        
                        segments.append(segment_data)
                        pos += 2 + length
                    else:
                        # Incomplete segment, move to next byte
                        pos += 1
            
            results["segments"] = segments
            
            # Check for unusual number of comment segments
            comment_segments = [s for s in segments if s.get("marker_name") == "Comment"]
            if len(comment_segments) > 1:
                results["suspicious_comments"] = {
                    "count": len(comment_segments),
                    "reason": "Multiple comment segments may hide data"
                }
            
            # Check for unusual segment ordering or anomalies
            # A typical JPEG has: SOI -> APP0 (JFIF) -> optional APP segments -> DQT -> SOF -> DHT -> SOS -> image data -> EOI
            marker_sequence = [s.get("marker_name", "") for s in segments]
            
            if marker_sequence and marker_sequence[0] != "Start of Image":
                results["invalid_structure"] = "File doesn't start with SOI marker"
            
            # Check for excessively large segments
            large_segments = [s for s in segments if s.get("length", 0) > 20000 and s.get("marker_name") not in ["Start of Scan", "Define Quantization Table"]]
            if large_segments:
                results["large_segments"] = {
                    "count": len(large_segments),
                    "info": [(s["marker_name"], s["length"]) for s in large_segments],
                    "reason": "Unusually large segments may contain hidden data"
                }
            
        except Exception as e:
            results["error"] = f"Error analyzing JPEG structure: {str(e)}"
        
        return results
    
    @staticmethod
    def get_jpeg_marker_name(marker):
        """Get JPEG marker name from bytes"""
        markers = {
            b'\xFF\xD8': "Start of Image",
            b'\xFF\xE0': "APP0 (JFIF)",
            b'\xFF\xE1': "APP1 (EXIF)",
            b'\xFF\xFE': "Comment",
            b'\xFF\xDB': "Define Quantization Table",
            b'\xFF\xC0': "Start of Frame (Baseline)",
            b'\xFF\xC2': "Start of Frame (Progressive)",
            b'\xFF\xC4': "Define Huffman Table",
            b'\xFF\xDA': "Start of Scan",
            b'\xFF\xD9': "End of Image"
        }
        
        return markers.get(marker, f"Unknown ({marker.hex()})")
    
    def analyze_png_file(self):
        """Analyze PNG file for anomalies and hidden content"""
        results = {}
        
        if not self.file_data.startswith(b'\x89PNG\r\n\x1A\n'):
            return {"error": "Not a valid PNG file"}
        
        # Parse PNG chunks
        chunks = []
        pos = 8  # Skip PNG signature
        
        try:
            while pos < len(self.file_data):
                # Read chunk length and type
                if pos + 8 > len(self.file_data):
                    break
                    
                chunk_length = struct.unpack('>I', self.file_data[pos:pos+4])[0]
                chunk_type = self.file_data[pos+4:pos+8].decode('ascii', errors='replace')
                
                # Load chunk data for certain chunks
                chunk_data = None
                if chunk_type in ['tEXt', 'iTXt', 'zTXt'] and pos + 8 + chunk_length <= len(self.file_data):
                    chunk_data = self.file_data[pos+8:pos+8+chunk_length]
                
                chunks.append({
                    "type": chunk_type,
                    "length": chunk_length,
                    "offset": pos,
                    "data": chunk_data
                })
                
                # End at IEND chunk
                if chunk_type == 'IEND':
                    break
                
                # Move to next chunk
                pos += 12 + chunk_length  # 4(length) + 4(type) + length + 4(crc)
        
        except Exception as e:
            return {"error": f"Error parsing PNG chunks: {str(e)}"}
        
        results["chunks"] = [{k:v for k,v in chunk.items() if k != 'data'} for chunk in chunks]  # Remove binary data from output
        
        # Check for unusual chunks
        standard_chunks = ['IHDR', 'PLTE', 'IDAT', 'IEND', 'tRNS', 'cHRM', 'gAMA', 'iCCP', 'sBIT', 'sRGB', 'tEXt', 'zTXt', 'iTXt', 'bKGD', 'pHYs', 'sPLT', 'hIST', 'tIME']
        
        unusual_chunks = [chunk for chunk in chunks if chunk["type"] not in standard_chunks]
        if unusual_chunks:
            results["unusual_chunks"] = {
                "count": len(unusual_chunks),
                "types": [c["type"] for c in unusual_chunks],
                "reason": "Non-standard chunks may hide data"
            }
        
        # Check text chunks for suspicious content
        text_chunks = [chunk for chunk in chunks if chunk["type"] in ['tEXt', 'iTXt', 'zTXt'] and chunk['data']]
        
        if text_chunks:
            suspicious_text_chunks = []
            
            for chunk in text_chunks:
                chunk_data = chunk['data']
                
                # For zTXt, decompress data
                if chunk["type"] == 'zTXt' and len(chunk_data) > 2:
                    try:
                        compression_method = chunk_data[0]
                        if compression_method == 0:  # zlib compression
                            # Find null separator and skip compression method byte
                            null_pos = chunk_data.find(b'\x00', 0) + 2
                            if null_pos > 1:
                                compressed_data = chunk_data[null_pos:]
                                chunk_data = zlib.decompress(compressed_data)
                    except:
                        pass
                
                # Check for code signatures in text
                for sig_name, pattern in self.code_signatures.items():
                    if pattern.search(chunk_data):
                        suspicious_text_chunks.append({
                            "chunk_type": chunk["type"],
                            "length": chunk["length"],
                            "detected_content": sig_name
                        })
                        break
            
            if suspicious_text_chunks:
                results["suspicious_text_chunks"] = suspicious_text_chunks
                results["text_chunk_risk"] = "High - detected code in text chunks"
            
        # Check for excessive IDAT chunks (could hide data in chunk fragmentation)
        idat_chunks = [chunk for chunk in chunks if chunk["type"] == 'IDAT']
        if len(idat_chunks) > 20:  # Arbitrary threshold
            results["excessive_idat_chunks"] = {
                "count": len(idat_chunks),
                "reason": "Excessive number of IDAT chunks may indicate hidden data in fragmentation"
            }
        
        return results
    
    def analyze_gif_file(self):
        """Analyze GIF file for anomalies and hidden content"""
        results = {}
        
        if not (self.file_data.startswith(b'GIF87a') or self.file_data.startswith(b'GIF89a')):
            return {"error": "Not a valid GIF file"}
        
        # Check for application extensions which might hide data
        app_ext_pattern = re.compile(rb'\x21\xFF\x0B[^\x00]+\x00', re.DOTALL)
        app_extensions = app_ext_pattern.findall(self.file_data)
        
        if app_extensions:
            results["application_extensions"] = {
                "count": len(app_extensions),
                "preview": [ext[3:15].decode('ascii', errors='replace') for ext in app_extensions]
            }
        
        # Check for comment extensions
        comment_pattern = re.compile(rb'\x21\xFE(.)((?:(?!\x00).){1,255})\x00', re.DOTALL)
        comments = comment_pattern.findall(self.file_data)
        
        if comments:
            results["comments"] = {
                "count": len(comments),
                "sample": [c[1][:50].decode('ascii', errors='replace') for c in comments[:3]]
            }
            
            # Check for suspicious patterns in comments
            suspicious_comments = []
            for _, comment in comments:
                for sig_name, pattern in self.code_signatures.items():
                    if pattern.search(comment):
                        suspicious_comments.append({
                            "detected_content": sig_name,
                            "preview": comment[:30].decode('ascii', errors='replace')
                        })
                        break
            
            if suspicious_comments:
                results["suspicious_comments"] = suspicious_comments
                results["comment_risk"] = "High - detected code patterns in comments"
        
        # Check for trailer inconsistency (missing/multiple trailers)
        trailers = self.file_data.count(b'\x3B')  # GIF trailer byte
        if trailers == 0:
            results["structure_anomaly"] = "Missing GIF trailer"
        elif trailers > 1:
            results["structure_anomaly"] = f"Multiple GIF trailers ({trailers})"
        
        return results
    
    def check_for_malicious_code(self):
        """Scan for known malicious code patterns in the image"""
        results = {"detected_patterns": []}
        
        # Check each signature
        for sig_name, pattern in self.code_signatures.items():
            matches = pattern.findall(self.file_data)
            
            if matches:
                # Found a suspicious pattern
                result = {
                    "signature_name": sig_name,
                    "matches_found": len(matches),
                    "sample_matches": [m[:50].decode('utf-8', errors='replace') + "..." for m in matches[:3]]
                }
                results["detected_patterns"].append(result)
        
        # Check for file inclusion attempts
        inclusion_matches = self.inclusion_patterns.findall(self.file_data)
        if inclusion_matches:
            results["detected_patterns"].append({
                "signature_name": "file_inclusion",
                "matches_found": len(inclusion_matches),
                "sample_matches": [m[:50].decode('utf-8', errors='replace') + "..." for m in inclusion_matches[:3]]
            })
        
        # Check for network connectivity attempts
        network_matches = self.network_patterns.findall(self.file_data)
        if network_matches:
            results["detected_patterns"].append({
                "signature_name": "network_communication",
                "matches_found": len(network_matches),
                "sample_matches": [m[:50].decode('utf-8', errors='replace') + "..." for m in network_matches[:3]]
            })
        
        # Overall assessment
        if results["detected_patterns"]:
            count = len(results["detected_patterns"])
            pattern_types = [p["signature_name"] for p in results["detected_patterns"]]
            
            if count >= 3 or "executable_header" in pattern_types or "php_code" in pattern_types:
                results["malicious_likelihood"] = "High"
            elif count >= 1:
                results["malicious_likelihood"] = "Medium"
            else:
                results["malicious_likelihood"] = "Low"
            
            results["summary"] = f"Detected {count} different types of potentially malicious code patterns"
        else:
            results["malicious_likelihood"] = "Very Low"
            results["summary"] = "No malicious code patterns detected"
            
        return results
    
    def analyze_metadata(self):
        """Analyze image metadata for suspicious content"""
        results = {}
        img_format = self.results["file_verification"]["detected_format"]
        
        # For JPEGs, check EXIF and other metadata
        if img_format == "jpeg":
            # Basic check for EXIF marker
            if b'\xFF\xE1' in self.file_data:
                exif_pos = self.file_data.find(b'\xFF\xE1')
                if exif_pos + 4 < len(self.file_data):
                    exif_length = struct.unpack('>H', self.file_data[exif_pos+2:exif_pos+4])[0]
                    
                    # Check for overflow
                    if exif_pos + 2 + exif_length <= len(self.file_data):
                        exif_data = self.file_data[exif_pos+4:exif_pos+2+exif_length]
                        
                        # Check if it's an EXIF header
                        if exif_data.startswith(b'Exif\x00\x00'):
                            results["exif_found"] = True
                            results["exif_length"] = exif_length
                            
                            # Check for executable code in EXIF
                            for sig_name, pattern in self.code_signatures.items():
                                if pattern.search(exif_data):
                                    results["suspicious_exif"] = {
                                        "reason": f"Found {sig_name} code pattern in EXIF data"
                                    }
                                    break
        
        # For PNGs, we've already analyzed text chunks in analyze_png_file()
        
        # File size anomaly check
        file_size = len(self.file_data)
        file_extension = os.path.splitext(self.file_path)[1].lower()
        
        # Very rough size estimates for suspicious image sizes
        suspicious_sizes = {
            ".jpg": 10 * 1024 * 1024,  # 10 MB
            ".jpeg": 10 * 1024 * 1024,
            ".png": 15 * 1024 * 1024,  # 15 MB
            ".gif": 20 * 1024 * 1024,  # 20 MB
            ".bmp": 30 * 1024 * 1024,  # 30 MB
        }
        
        if file_extension in suspicious_sizes and file_size > suspicious_sizes[file_extension]:
            results["size_anomaly"] = {
                "file_size": file_size,
                "threshold": suspicious_sizes[file_extension],
                "reason": "File is unusually large for its format, may contain hidden data"
            }
        
        return results
    
    def check_for_hidden_data(self):
        """Detect potential hidden data beyond standard steganography techniques"""
        results = {}
        
        # Check file size vs expected size based on dimensions (for certain formats)
        img_format = self.results["file_verification"]["detected_format"]
        
        # For PNGs, check IHDR dimensions vs file size
        if img_format == "png":
            # Find IHDR chunk
            ihdr_pos = self.file_data.find(b'IHDR')
            if ihdr_pos > 0 and ihdr_pos + 16 < len(self.file_data):
                try:
                    width = struct.unpack('>I', self.file_data[ihdr_pos-4:ihdr_pos])[0]
                    height = struct.unpack('>I', self.file_data[ihdr_pos+4:ihdr_pos+8])[0]
                    bit_depth = self.file_data[ihdr_pos+8]
                    color_type = self.file_data[ihdr_pos+9]
                    
                    results["dimensions"] = {
                        "width": width,
                        "height": height,
                        "bit_depth": bit_depth,
                        "color_type": color_type
                    }
                    
                    # Calculate expected size range
                    # This is a rough estimate and depends on compression efficiency
                    bytes_per_pixel = bit_depth / 8
                    if color_type == 2:  # RGB
                        bytes_per_pixel *= 3
                    elif color_type == 6:  # RGBA
                        bytes_per_pixel *= 4
                    
                    raw_size = width * height * bytes_per_pixel
                    min_expected = raw_size / 10  # Assume good compression
                    max_expected = raw_size / 2   # Assume poor compression
                    
                    file_size = len(self.file_data)
                    
                    if file_size > max_expected * 1.5:
                        results["size_anomaly"] = {
                            "actual_size": file_size,
                            "expected_max": max_expected,
                            "ratio": file_size / max_expected,
                            "reason": "File is much larger than expected for its dimensions"
                        }
                except:
                    results["dimensions_error"] = "Error parsing PNG dimensions"
        
        # Check for entropy variations in different parts of the file
        section_size = min(1024, len(self.file_data) // 10)  # 1KB sections or smaller for small files
        section_entropies = []
        
        for i in range(0, len(self.file_data), section_size):
            section = self.file_data[i:i+section_size]
            if len(section) > 20:  # Only analyze sections with sufficient data
                section_entropy = self.shannon_entropy(section)
                section_entropies.append(section_entropy)
        
        if section_entropies:
            results["section_entropy"] = {
                "values": section_entropies,
                "average": sum(section_entropies) / len(section_entropies),
                "max": max(section_entropies),
                "min": min(section_entropies),
                "variance": max(section_entropies) - min(section_entropies)
            }
            
            # Look for high entropy sections after expected data
            if max(section_entropies) > 7.8 and results["section_entropy"]["variance"] > 1.0:
                high_entropy_sections = [i for i, e in enumerate(section_entropies) if e > 7.5]
                results["section_entropy"]["high_entropy_sections"] = high_entropy_sections
                
               # Check if high entropy sections are at the end
                if high_entropy_sections and max(high_entropy_sections) >= len(section_entropies) - 3:
                    results["section_entropy"]["assessment"] = "High entropy data found near end of file, possible hidden content"
                elif high_entropy_sections:
                    results["section_entropy"]["assessment"] = "High entropy sections found scattered throughout file"
        
        # Check for potential polyglot files (files that are valid as multiple formats)
        polyglot_indicators = []
        
        # Check for ZIP signatures (PK..)
        if b'PK\x03\x04' in self.file_data and not self.file_data.startswith(b'PK\x03\x04'):
            polyglot_indicators.append("ZIP archive signature found inside image")
        
        # Check for PDF signature
        if b'%PDF-' in self.file_data and not self.file_data.startswith(b'%PDF-'):
            polyglot_indicators.append("PDF signature found inside image")
        
        # Check for HTML/XML
        if b'<!DOCTYPE' in self.file_data or b'<html' in self.file_data:
            polyglot_indicators.append("HTML content found inside image")
        
        # Check for other executable formats
        if b'MZ' in self.file_data[50:] or b'\x7FELF' in self.file_data[50:]:
            polyglot_indicators.append("Executable signature found inside image")
        
        if polyglot_indicators:
            results["polyglot_indicators"] = polyglot_indicators
        
        return results
    
    @staticmethod
    def shannon_entropy(data):
        """Calculate Shannon entropy of data"""
        if not data:
            return 0
            
        # Create a frequency count of bytes
        byte_counts = Counter(data)
        filesize = len(data)
        
        # Calculate entropy
        entropy = 0
        for count in byte_counts.values():
            probability = count / filesize
            entropy -= probability * math.log2(probability)
                
        return entropy
    
    def assess_risk(self):
        """Perform overall risk assessment based on all analysis results"""
        risk_score = 0
        risk_factors = []
        
        # Check for file type inconsistencies
        file_verification = self.results.get("file_verification", {})
        if file_verification.get("extension_mismatch"):
            risk_score += 15
            risk_factors.append("File extension doesn't match image format")
        
        # Check for malicious code patterns
        malicious_code = self.results.get("malicious_code_check", {})
        detected_patterns = len(malicious_code.get("detected_patterns", []))
        
        if detected_patterns > 0:
            if malicious_code.get("malicious_likelihood") == "High":
                risk_score += 40
                risk_factors.append(f"High likelihood of malicious code - detected {detected_patterns} suspicious patterns")
            elif malicious_code.get("malicious_likelihood") == "Medium":
                risk_score += 25
                risk_factors.append(f"Medium likelihood of malicious code - detected {detected_patterns} suspicious patterns")
            else:
                risk_score += 10
                risk_factors.append(f"Detected {detected_patterns} potentially suspicious code patterns")
        
        # Check for steganography indicators
        steganography = self.results.get("steganography_analysis", {})
        
        # Check for appended data
        if steganography.get("appended_data", {}).get("found"):
            appended_data = steganography.get("appended_data", {})
            content_indicators = appended_data.get("content_indicators", [])
            
            if any("executable" in indicator.lower() for indicator in content_indicators):
                risk_score += 40
                risk_factors.append("Executable code appended to image file")
            elif any("php code" in indicator.lower() or "script" in indicator.lower() for indicator in content_indicators):
                risk_score += 35
                risk_factors.append("Script code appended to image file")
            else:
                risk_score += 25
                risk_factors.append(f"Data found after image ending ({appended_data.get('size', 0)} bytes)")
        
        # Check entropy
        if steganography.get("overall_entropy", 0) > 7.8:
            risk_score += 20
            risk_factors.append("Extremely high entropy indicating possible encryption or hidden content")
        
        # Format specific checks
        if "jpeg_analysis" in steganography:
            jpeg = steganography.get("jpeg_analysis", {})
            if jpeg.get("suspicious_comments", {}).get("count", 0) > 1:
                risk_score += 15
                risk_factors.append(f"Multiple JPEG comment segments ({jpeg.get('suspicious_comments', {}).get('count', 0)})")
            
            if jpeg.get("large_segments"):
                risk_score += 10
                risk_factors.append("Unusually large JPEG segments detected")
        
        elif "png_analysis" in steganography:
            png = steganography.get("png_analysis", {})
            if png.get("unusual_chunks"):
                risk_score += 15
                risk_factors.append(f"Unusual PNG chunks found: {', '.join(png.get('unusual_chunks', {}).get('types', []))}")
            
            if png.get("suspicious_text_chunks"):
                risk_score += 25
                risk_factors.append("Code detected in PNG text chunks")
            
            if png.get("excessive_idat_chunks"):
                risk_score += 10
                risk_factors.append(f"Excessive IDAT chunks ({png.get('excessive_idat_chunks', {}).get('count', 0)})")
        
        # Check for hidden data
        hidden_data = self.results.get("hidden_data_analysis", {})
        
        if hidden_data.get("size_anomaly"):
            risk_score += 15
            risk_factors.append("File size much larger than expected for dimensions")
        
        if hidden_data.get("polyglot_indicators"):
            risk_score += 20
            risk_factors.append(f"Multiple file format signatures found: {', '.join(hidden_data.get('polyglot_indicators', []))}")
        
        section_entropy = hidden_data.get("section_entropy", {})
        if section_entropy.get("assessment") and "possible hidden content" in section_entropy.get("assessment"):
            risk_score += 15
            risk_factors.append("High entropy sections found near end of file")
        
        # Determine risk level
        if risk_score >= 70:
            risk_level = "Critical"
        elif risk_score >= 50:
            risk_level = "High"
        elif risk_score >= 30:
            risk_level = "Medium"
        elif risk_score >= 10:
            risk_level = "Low"
        else:
            risk_level = "Minimal"
        
        return {
            "risk_score": risk_score,
            "risk_level": risk_level,
            "risk_factors": risk_factors,
            "recommendation": self.get_recommendation(risk_level)
        }
    
    @staticmethod
    def get_recommendation(risk_level):
        """Generate recommendation based on risk level"""
        if risk_level == "Critical":
            return "DANGER: This image contains clear evidence of malicious code. Do not open or execute this file under any circumstances."
        elif risk_level == "High":
            return "WARNING: This image contains highly suspicious elements indicating potential malware. Do not open this file outside a secure sandbox environment."
        elif risk_level == "Medium":
            return "CAUTION: This image contains some suspicious characteristics. View this file only using trusted image viewers with updated security patches."
        elif risk_level == "Low":
            return "NOTICE: This image has minor suspicious indicators. Avoid executing or opening with non-standard applications."
        else:  # Minimal
            return "This image appears normal with no significant malicious indicators detected. Standard safety precautions advised."

    def create_report(self):
        """Create a readable report from the analysis results"""
        if not self.results:
            return "No analysis results available. Please run analyze_image() first."
        
        report = []
        report.append("=" * 60)
        report.append("IMAGE MALWARE DETECTION REPORT")
        report.append("=" * 60)
        
        # File information
        report.append(f"\nFile: {os.path.basename(self.file_path)}")
        report.append(f"Size: {len(self.file_data) / 1024:.2f} KB")
        
        # Risk assessment
        risk = self.results.get("risk_assessment", {})
        if risk:
            report.append(f"\nRISK ASSESSMENT: {risk.get('risk_level', 'Unknown')}")
            report.append(f"Risk Score: {risk.get('risk_score', 0)}/100")
            report.append("\nRisk Factors:")
            for factor in risk.get("risk_factors", []):
                report.append(f"- {factor}")
            
            report.append(f"\nRECOMMENDATION: {risk.get('recommendation', '')}")
        
        # File verification
        file_info = self.results.get("file_verification", {})
        report.append("\nFILE VERIFICATION:")
        report.append(f"Detected Format: {file_info.get('detected_format', 'Unknown')}")
        report.append(f"File Extension: {file_info.get('file_extension', 'Unknown')}")
        
        if file_info.get("extension_mismatch"):
            report.append(f"WARNING: Extension mismatch - Expected: {', '.join(file_info.get('expected_extensions', []))}")
        
        # Malicious code check
        code_check = self.results.get("malicious_code_check", {})
        report.append("\nMALICIOUS CODE CHECK:")
        report.append(f"Result: {code_check.get('summary', 'Not available')}")
        
        if code_check.get("detected_patterns"):
            report.append("\nDetected Patterns:")
            for pattern in code_check.get("detected_patterns", []):
                report.append(f"- {pattern['signature_name']}: {pattern['matches_found']} matches")
                if pattern.get("sample_matches"):
                    report.append(f"  Sample: {pattern['sample_matches'][0]}")
        
        # Steganography analysis
        stego = self.results.get("steganography_analysis", {})
        report.append("\nSTEGANOGRAPHY ANALYSIS:")
        report.append(f"Entropy: {stego.get('overall_entropy', 0):.4f} - {stego.get('entropy_assessment', 'Unknown')}")
        
        if stego.get("appended_data", {}).get("found"):
            appended = stego.get("appended_data", {})
            report.append(f"\nAppended Data Found: {appended.get('size', 0)} bytes after end of image")
            if appended.get("content_indicators"):
                report.append(f"Content Type: {', '.join(appended.get('content_indicators', []))}")
        
        # Hidden data analysis
        hidden = self.results.get("hidden_data_analysis", {})
        if hidden.get("polyglot_indicators"):
            report.append("\nPOLYGLOT FILE INDICATORS:")
            for indicator in hidden.get("polyglot_indicators", []):
                report.append(f"- {indicator}")
        
        # Final summary
        report.append("\n" + "=" * 60)
        if risk.get('risk_level') in ["Critical", "High"]:
            report.append("WARNING: THIS FILE IS LIKELY MALICIOUS")
        report.append("=" * 60)
        
        return "\n".join(report)


if __name__ == "__main__":
    # Example usage
    import sys
    
    if len(sys.argv) != 2:
        print("Usage: python image_malware_detection.py <image_file_path>")
        sys.exit(1)
    
    file_path = sys.argv[1]
    
    # Initialize and run analysis
    detector = ImageMalwareDetection(file_path)
    detector.analyze_image()
    
    # Print report
    print(detector.create_report())